{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0e677-6af3-4566-b500-090bd4c537b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/Tencent/HunyuanVideo\n",
    "\n",
    "#screen\n",
    "apt-get update && apt-get install -y screen\n",
    "screen\n",
    "\n",
    "#开启学术加速\n",
    "source /etc/network_turbo\n",
    "#关闭学术加速\n",
    "unset http_proxy && unset https_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210ed9b0-a1ce-4afc-ae24-f1fb35281bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#安装虚拟环境到数据盘\n",
    "#执行以下命令设置将虚拟环境安装到/root/autodl-tmp/conda/envs， 包缓存到/root/autodl-tmp/conda/pkgs\n",
    "mkdir -p /root/autodl-tmp/conda/pkgs\n",
    "conda config --add pkgs_dirs /root/autodl-tmp/conda/pkgs\n",
    "mkdir -p /root/autodl-tmp/conda/envs\n",
    "conda config --add envs_dirs /root/autodl-tmp/conda/envs\n",
    "# 创建新的site_packages目录\n",
    "mkdir -p /path/to/new/site_packages\n",
    "# 设置环境变量PYTHONUSERBASE\n",
    "export PYTHONUSERBASE=/path/to/new\n",
    "# 安装包到新的site_packages目录\n",
    "pip install --user package_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e0378-01b5-43cd-83cc-93fd78404eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare conda environment\n",
    "conda env create -f environment.yml\n",
    "\n",
    "# 2. Activate the environment\n",
    "conda activate HunyuanVideo\n",
    "\n",
    "# 3. Install pip dependencies\n",
    "python -m pip install -r requirements.txt\n",
    "\n",
    "# 4. Install flash attention v2 for acceleration (requires CUDA 11.8 or above)\n",
    "python -m pip install ninja\n",
    "python -m pip install git+https://github.com/Dao-AILab/flash-attention.git@v2.5.9.post1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c8aabb-3bbc-48d1-99c4-b1b8068128fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#安装 flash attention v2 用于加速 (要求 CUDA 11.8 或更高)\n",
    "python -m pip install git+https://github.com/Dao-AILab/flash-attention.git@v2.5.9.post1\n",
    "\n",
    "#所有模型默认存储在HunyuanVideo/ckpts中\n",
    "#要下载浑源视频模型，请先安装huggingface-插件\n",
    "python -m pip install \"huggingface_hub[cli]\"\n",
    "#huggingface-cli download tencent/HunyuanVideo --local-dir ./ckpts\n",
    "huggingface-cli download tencent/HunyuanVideo --local-dir /root/autodl-tmp/ckpts\n",
    "\n",
    "#推荐社区用户使用Xtuer提供的llava-llama-3-8b，可通过以下命令下载\n",
    "#MLLM模型（text_encoder文件夹）\n",
    "cd HunyuanVideo/ckpts\n",
    "huggingface-cli download xtuner/llava-llama-3-8b-v1_1-transformers --local-dir ./llava-llama-3-8b-v1_1-transformers\n",
    "huggingface-cli download xtuner/llava-llama-3-8b-v1_1-transformers --local-dir /root/autodl-tmp/ckpts/llava-llama-3-8b-v1_1-transformers\n",
    "\n",
    "\n",
    "#为了节省模型加载的GPU内存资源，我们将llava-llama-3-8b-v1_1-transformers的语言模型部分分离到text_encoder中。\n",
    "cd HunyuanVideo\n",
    "python hyvideo/utils/preprocess_text_encoder_tokenizer_utils.py --input_dir /root/autodl-tmp/ckpts/llava-llama-3-8b-v1_1-transformers --output_dir /root/autodl-tmp/ckpts/text_encoder\n",
    "\n",
    "#CLIP模型（text_encoder_2文件夹）\n",
    "cd HunyuanVideo/ckpts\n",
    "huggingface-cli download openai/clip-vit-large-patch14 --local-dir /root/autodl-tmp/ckpts/text_encoder_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63bfea-e42b-4f19-baab-9bf6a4a4e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd HunyuanVideo\n",
    "\n",
    "python sample_video.py \\\n",
    "    --video-size 544 960 \\\n",
    "    --video-length 129 \\\n",
    "    --infer-steps 10 \\\n",
    "    --prompt \"一个老人坐在海边长椅上看日落，背影显得孤寂悲凉\" \\\n",
    "    --flow-reverse \\\n",
    "    --use-cpu-offload \\\n",
    "    --save-path ./results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d880c3b-be32-4ebb-9b50-8f4a80cb2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "参数  默认值 描述\n",
    "--prompt    没有一 用于生成视频的 prompt\n",
    "--video-size    720 1280    生成视频的高度和宽度\n",
    "--video-length  129 生成视频的帧数\n",
    "--infer-steps   50  生成时采样的步数\n",
    "--embedded-cfg-scale    6.0 文本的控制强度\n",
    "--flow-shift    7.0 推理时 timestep 的 shift 系数，值越大，高噪区域采样步数越多\n",
    "--flow-reverse  假   如果相反，则从t=1 -> t=0学习/采样\n",
    "--neg-prompt    没有一 负向词\n",
    "--seed  0   随机种子\n",
    "--use-cpu-offload   假   启用 CPU offload，可以节省显存\n",
    "--save-path ./结果    保存路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22928aec-72ed-4f13-8b2a-1bfbd8ea92fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a Gradio Server\n",
    "python gradio_server.py --flow-reverse\n",
    "# set SERVER_NAME and SERVER_PORT manually\n",
    "# SERVER_NAME=0.0.0.0 SERVER_PORT=8081 python3 gradio_server.py --flow-reverse\n",
    "\n",
    "ssh -CNg -L 6006:127.0.0.1:6006 root@123.125.240.150 -p 42151\n",
    "ssh -CNg -L 8081:127.0.0.1:8081 root@connect.bjc1.seetacloud.com -p 10514 \n",
    "#ssh -p 10514 root@connect.bjc1.seetacloud.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721e885-0f7e-4a03-a779-c63c50091a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
